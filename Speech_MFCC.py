# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vr3-64vxSanXuprouD5jT50g0pmUiWcy
"""

# Commented out IPython magic to ensure Python compatibility.
#Run below lines of code only when using Google Colab
!pip install python_speech_features
!pip install soundfile
# %tensorflow_version 2.x
from google.colab import drive
drive.mount('/content/drive')
#Main program
import os
import csv
import pickle
import librosa
import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy.io import wavfile
import IPython.display as ipd
import matplotlib.pyplot as plt
from keras.utils import to_categorical
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
from python_speech_features import mfcc, logfbank
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import TensorBoard, EarlyStopping
from tensorflow.keras.layers import Dropout, Dense, TimeDistributed
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM
#Creating .csv file that has location, label of all the audio files
base_dirs='/content/drive/My Drive/Colab Notebooks/wavefiles'
labels =['down','left','right','up']
with open('/content/drive/My Drive/Colab Notebooks/wavefile.csv', 'w') as csvf
ile:
filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.Q
UOTE_MINIMAL)
filewriter.writerow(["fname", "label"])
for lbl in labels:
p=os.path.join(base_dirs,lbl)
for wv in os.listdir(p):
filewriter.writerow([p+'/'+wv, lbl])
csvfile.close()
#Down sampling files from 16KHz to 8Khz
for files in tqdm(df.index):
samples, sample_rate = librosa.load(files, sr = 16000)
samples = librosa.resample(samples, sample_rate, 8000)
sr=8000librosa.output.write_wav(files, samples, sr)
#Finding the length of each audio file
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/wavefile.csv')
df.set_index('fname', inplace=True)
for f in tqdm(df.index):
rate, signal = wavfile.read(f)
df.at[f, 'length'] = signal.shape[0]/rate
#Saving the dataframe object
with open('/content/drive/My Drive/Colab Notebooks/df.pickle', 'wb') as f:
pickle.dump(df, f)
with open('/content/drive/My Drive/Colab Notebooks/df.pickle', 'rb') as f:
df = pickle.load(f)
#Finding the class distribution
class_dist = df.groupby(['label'])['length'].mean()
fig, ax = plt.subplots()
ax.set_title('Class Distribution', y=1.08)
ax.pie(class_dist, labels=class_dist.index, autopct='%1.1f%%', shadow=False, s
tartangle=90)
ax.axis('equal')
plt.show()
df.reset_index(inplace=True)
#Creating all the models
#LSTM
def get_recurrent_model():
model = Sequential()
model.add(LSTM(64,return_sequences=True, input_shape = input_shape))
model.add(LSTM(64,return_sequences=True))
model.add(Flatten())
model.add(Dense(64, activation
model.add(Dense(64, activation
model.add(Dense(64, activation
model.add(Dense(64, activation
model.add(Dropout(0.3))
='relu'))
='relu'))
='relu'))
='relu'))
model.add(Dense(4, activation ='softmax'))
adam = optimizers.Adam(lr = 0.002)
model.summary()
model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc
uracy'])return model
#CNN
def get_conv_model():
model = Sequential()
model.add(Conv2D(64, (3,3), padding='valid', activation='relu', input_shape =
input_shape))
model.add(Conv2D(64, (3,3), padding='valid', activation='relu'))
model.add(Conv2D(64, (3,3), padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(len(labels), activation='softmax'))
adam = optimizers.Adam(lr = 0.002)
model.summary()
model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['cate
gorical_accuracy'])
return model
#CNN+LSTM
def get_convtime_model():
model = Sequential()
model.add(Conv1D(64, 3, activation='relu', input_shape = input_shape))
model.add(Conv1D(64, 3, activation='relu'))
model.add(Conv1D(64, 3, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(16, return_sequences=True))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))model.add(Dense(len(labels), activation='softmax'))
adam = optimizers.Adam(lr = 0.002)
model.summary()
model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['cate
gorical_accuracy'])
return model
#Finding MFCC features
df.set_index('fname', inplace=True)
def build_rand_feat():
x=[]
y=[]
_min, _max = float('inf'), -float('inf')
for _ in tqdm(range(n_samples)):
rand_class = np.random.choice(class_dist.index, p=prob_dist)
file = np.random.choice(df[df.label==rand_class].index)
rate, wav = wavfile.read(file)
label = df.at[file, 'label']
sample = wav[:rate]
x_sample = mfcc(sample, rate, numcep = config.nfeat, nfilt = config.nfilt,
nfft = config.nfft).T
_min = min(np.amin(x_sample),_min)
_max = max(np.amax(x_sample),_max)
x.append(x_sample if config.mode == 'conv' else x_sample.T)
y.append(labels.index(label))
x,y = np.array(x), np.array(y)
x = (x - _min)/(_max - _min)
if config.mode == 'conv':
x = x.reshape(x.shape[0], x.shape[1], x.shape[2],1)
else:
x= x.reshape(x.shape[0], x.shape[1], x.shape[2])
y = to_categorical(y, num_classes = 4)
return x,y
class Config:
def __init__(self, mode='conv', nfilt =26, nfeat=13, nfft=512, rate = 8000):
self.mode = mode
self.nfilt = nfilt
self.nfeat = nfeat
self.nfft = nfft
self.rate = rateself.step = int(rate/10)
n_samples = 2*int(df['length'].sum()/0.1)
prob_dist = class_dist/class_dist.sum()
config = Config(mode='conv')
if config.mode == 'conv':
x,y = build_rand_feat()
input_shape = (x.shape[1], x.shape[2], 1)
else:
x,y = build_rand_feat()
input_shape = (x.shape[1], x.shape[2])
#Saving prepreocessed audio dataset
if config.mode == 'conv':
with open('/content/drive/My Drive/Colab Notebooks/xyconv.pickle', 'wb') as
f:
pickle.dump([x,y], f)
else:
with open('/content/drive/My Drive/Colab Notebooks/xytime.pickle', 'wb') as
f:
pickle.dump([x,y], f)
if config.mode == 'conv':
with open('/content/drive/My Drive/Colab Notebooks/xyconv', 'rb') as f:
x,y = pickle.load(f)
else:
with open('/content/drive/My Drive/Colab Notebooks/xytime.pickle', 'rb') as f:
x,y = pickle.load(f)
#Selecting which model to run
if config.mode == 'conv':
model=get_conv_model()
elif config.mode == 'time':
model = get_recurrent_model()
elif config.mode == 'convtime':
model = get_convtime_model()
#Callbacks
tensorboard = TensorBoard(log_dir="/content/drive/My Drive/Colab Notebooks/
logs/")
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min
_delta=0.0001)#Splitting into test and train dataset
x_tr, x_val, y_tr, y_val = train_test_split(x,y,test_size = 0.2,random_state=7
77, shuffle=True)
#Training the selected model
model.fit(x_tr, y_tr, epochs=100, batch_size = 32, validation_split= 0.1, call
backs=[tensorboard, es])
#Evaluating the selected model
model.evaluate(x_val, y_val, batch_size=32)