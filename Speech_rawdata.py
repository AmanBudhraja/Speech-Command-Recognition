# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vr3-64vxSanXuprouD5jT50g0pmUiWcy
"""

#Code for CNN model with raw audio data as input
import os
import csv
import pickle
import librosa
import numpy as np
import pandas as pd
from tqdm import tqdm
import soundfile as sf
from scipy.io import wavfile
import IPython.display as ipd
import matplotlib.pyplot as plt
from keras.utils import np_utils
from keras.utils import to_categorical
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
from python_speech_features import mfcc, logfbank
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import TensorBoard, EarlyStopping
from tensorflow.keras.layers import Dropout, Dense, TimeDistributed
from tensorflow.keras.layers import Flatten, Conv1D, MaxPooling1D
train_audio_path = '/content/drive/My Drive/Colab Notebooks/wavefiles/'
labels=["up", "down", "left", "right"]
#Reading audio files
all_wave = []
all_label = []
for label in labels:
waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith(
'.wav')]
for wav in tqdm(waves):samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' +
wav, sr = 8000)
if(len(samples)== 8000) :
all_wave.append(samples)
all_label.append(label)
#One-hot encoding
le = LabelEncoder()
y=le.fit_transform(all_label)
classes= list(le.classes_)
y=np_utils.to_categorical(y, num_classes=len(labels))
all_wave = np.array(all_wave).reshape(-1,8000,1)
x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),str
atify=y,test_size = 0.2,random_state=777,shuffle=True)
inputs = x_tr.shape[1:]
#CNN
model = Sequential()
model.add(Conv1D(8,13, padding='valid', activation='relu', strides=1, input_sh
ape = inputs))
model.add(MaxPooling1D(3))
model.add(Dropout(0.3))
model.add(Conv1D(16, 11, padding='valid', activation='relu', strides=1))
model.add(MaxPooling1D(3))
model.add(Dropout(0.3))
model.add(Conv1D(32, 9, padding='valid', activation='relu', strides=1))
model.add(MaxPooling1D(3))
model.add(Dropout(0.3))
model.add(Conv1D(64, 7, padding='valid', activation='relu', strides=1))
model.add(MaxPooling1D(3))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(len(labels), activation='softmax'))
adam = optimizers.Adam(lr = 0.002)
model.summary()model.compile(loss='categorical_crossentropy',optimizer=adam ,metrics=['accura
cy'])
#Callbacks
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min
_delta=0.0001)
tensorboard = TensorBoard(log_dir = '/content/drive/My Drive/Colab Notebooks/
conv1d/')
#Training the model
model.fit(x_tr, y_tr ,epochs=100, callbacks=[es, tensorboard], batch_size=32,
validation_split =0.1)
#Testing the model
model.evaluate(x_val,y_val, batch_size =32)